{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67fbacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px \n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from openai import OpenAI\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b18ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_path = r\"C:\\Users\\Ayman\\Downloads\\archive (90)\\bbc\"\n",
    "\n",
    "data = []\n",
    "\n",
    "for category in os.listdir(base_path):\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        for file_name in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "            with open(file_path, 'r', encoding='latin1') as f:\n",
    "                content = f.read()\n",
    "                data.append((category, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b19d9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)\n",
    "df.columns=['category','Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce54daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  category\n",
       "0     Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1     Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2     Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3     High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4     Pernod takeover talk lifts Domecq\\n\\nShares in...  business\n",
       "...                                                 ...       ...\n",
       "2220  BT program to beat dialler scams\\n\\nBT is intr...      tech\n",
       "2221  Spam e-mails tempt net shoppers\\n\\nComputer us...      tech\n",
       "2222  Be careful how you code\\n\\nA new European dire...      tech\n",
       "2223  US cyber security chief resigns\\n\\nThe man mak...      tech\n",
       "2224  Losing yourself in online gaming\\n\\nOnline rol...      tech\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['Text','category']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb9ef6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('news_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf9285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"clean_text\"] = df[\"Text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1608baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "      <td>dollar gain greenspan speech dollar hit highes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "      <td>tech</td>\n",
       "      <td>bt program beat dialler scam bt introducing tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
       "      <td>tech</td>\n",
       "      <td>spam email tempt net shopper computer user acr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "      <td>tech</td>\n",
       "      <td>careful code new european directive could put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>tech</td>\n",
       "      <td>u cyber security chief resigns man making sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "      <td>tech</td>\n",
       "      <td>losing online gaming online role playing game ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  category  \\\n",
       "0     Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "1     Dollar gains on Greenspan speech\\n\\nThe dollar...  business   \n",
       "2     Yukos unit buyer faces loan claim\\n\\nThe owner...  business   \n",
       "3     High fuel prices hit BA's profits\\n\\nBritish A...  business   \n",
       "4     Pernod takeover talk lifts Domecq\\n\\nShares in...  business   \n",
       "...                                                 ...       ...   \n",
       "2220  BT program to beat dialler scams\\n\\nBT is intr...      tech   \n",
       "2221  Spam e-mails tempt net shoppers\\n\\nComputer us...      tech   \n",
       "2222  Be careful how you code\\n\\nA new European dire...      tech   \n",
       "2223  US cyber security chief resigns\\n\\nThe man mak...      tech   \n",
       "2224  Losing yourself in online gaming\\n\\nOnline rol...      tech   \n",
       "\n",
       "                                             clean_text  \n",
       "0     ad sale boost time warner profit quarterly pro...  \n",
       "1     dollar gain greenspan speech dollar hit highes...  \n",
       "2     yukos unit buyer face loan claim owner embattl...  \n",
       "3     high fuel price hit ba profit british airway b...  \n",
       "4     pernod takeover talk lift domecq share uk drin...  \n",
       "...                                                 ...  \n",
       "2220  bt program beat dialler scam bt introducing tw...  \n",
       "2221  spam email tempt net shopper computer user acr...  \n",
       "2222  careful code new european directive could put ...  \n",
       "2223  u cyber security chief resigns man making sure...  \n",
       "2224  losing online gaming online role playing game ...  \n",
       "\n",
       "[2225 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72fb4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Text\"])\n",
    "\n",
    "# Store each row's vector as a list\n",
    "df[\"embedding\"] = list(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48b984b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "      <td>[0.0, 0.020867638057080935, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "      <td>dollar gain greenspan speech dollar hit highes...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "      <td>[0.0, 0.018988980429721043, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  category  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  ad sale boost time warner profit quarterly pro...   \n",
       "1  dollar gain greenspan speech dollar hit highes...   \n",
       "2  yukos unit buyer face loan claim owner embattl...   \n",
       "3  high fuel price hit ba profit british airway b...   \n",
       "4  pernod takeover talk lift domecq share uk drin...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0, 0.020867638057080935, 0.0, 0.0, 0.0, 0.0...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.018988980429721043, 0.0, 0.0, 0.0, 0.0...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def log_model(df, test_size):\n",
    "    X = np.array(df['embedding'].to_list())\n",
    "    y = df['category']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, shuffle=True, random_state=1, test_size=test_size\n",
    "    )\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "123b4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def nb_model(df, test_size):\n",
    "    X = np.array(df['embedding'].to_list())\n",
    "    y = df['category']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, shuffle=True, random_state=1, test_size=test_size\n",
    "    )\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "246ad23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.93      0.97      0.95        86\n",
      "entertainment       0.99      0.96      0.98        84\n",
      "     politics       0.98      0.97      0.97        92\n",
      "        sport       0.99      0.99      0.99        99\n",
      "         tech       0.98      0.98      0.98        84\n",
      "\n",
      "     accuracy                           0.97       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.97      0.97      0.97       445\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[83  0  1  1  1]\n",
      " [ 2 81  1  0  0]\n",
      " [ 2  0 89  0  1]\n",
      " [ 1  0  0 98  0]\n",
      " [ 1  1  0  0 82]]\n"
     ]
    }
   ],
   "source": [
    "model_Log=log_model(df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7d40493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.87      0.97      0.92        86\n",
      "entertainment       1.00      0.76      0.86        84\n",
      "     politics       0.94      0.97      0.95        92\n",
      "        sport       0.93      0.99      0.96        99\n",
      "         tech       0.95      0.98      0.96        84\n",
      "\n",
      "     accuracy                           0.93       445\n",
      "    macro avg       0.94      0.93      0.93       445\n",
      " weighted avg       0.94      0.93      0.93       445\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[83  0  1  1  1]\n",
      " [ 9 64  5  4  2]\n",
      " [ 1  0 89  1  1]\n",
      " [ 1  0  0 98  0]\n",
      " [ 1  0  0  1 82]]\n"
     ]
    }
   ],
   "source": [
    "model_nb=nb_model(df,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bade8e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved as model_Log.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "## Logisitic regression is better \n",
    "with open(\"model_Log.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_Log, f)\n",
    "\n",
    "print(\"âœ… Model saved as model_Log.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a1b0008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… vectorizer saved as model_Log.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "## Logisitic regression is better \n",
    "with open(\"vec.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(\"âœ… vectorizer saved as model_Log.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85578030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(df['category'].unique())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d1f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['Text'],  # Ù‡Ù†Ø§ ØªØ­Ø· Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†ØµÙŠ\n",
    "    df['category'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db188b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = torch.tensor(label_encoder.fit_transform(train_labels))\n",
    "val_labels = torch.tensor(label_encoder.transform(val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8c64ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx]) for key, val in self.encodings.items()\n",
    "        } | {\"labels\": self.labels[idx]}\n",
    "\n",
    "train_dataset = TextDataset(train_encodings, train_labels)\n",
    "val_dataset = TextDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7195348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayman\\anaconda3\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342721bdc86b45838fd042d86ccca39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a46f16cb6249bd8c005a9000b0ed4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14901427924633026, 'eval_runtime': 28.1293, 'eval_samples_per_second': 15.82, 'eval_steps_per_second': 0.995, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc456ce91774bdcb8fa4bf895a42d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0944007933139801, 'eval_runtime': 30.464, 'eval_samples_per_second': 14.607, 'eval_steps_per_second': 0.919, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac25ca8b1f74fae8d4b984e9fa753fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07018481194972992, 'eval_runtime': 30.4005, 'eval_samples_per_second': 14.638, 'eval_steps_per_second': 0.921, 'epoch': 3.0}\n",
      "{'train_runtime': 1533.7796, 'train_samples_per_second': 3.482, 'train_steps_per_second': 0.219, 'train_loss': 0.27876204536074684, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=336, training_loss=0.27876204536074684, metrics={'train_runtime': 1533.7796, 'train_samples_per_second': 3.482, 'train_steps_per_second': 0.219, 'total_flos': 176853438489600.0, 'train_loss': 0.27876204536074684, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a415b798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65df9be91a47490daf9e739b1373228d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.96      0.96       115\n",
      "entertainment       1.00      1.00      1.00        72\n",
      "     politics       0.96      0.99      0.97        76\n",
      "        sport       1.00      0.99      1.00       102\n",
      "         tech       0.97      0.97      0.97        80\n",
      "\n",
      "     accuracy                           0.98       445\n",
      "    macro avg       0.98      0.98      0.98       445\n",
      " weighted avg       0.98      0.98      0.98       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = trainer.predict(val_dataset)\n",
    "y_pred = predictions.predictions.argmax(axis=-1)\n",
    "y_true = val_labels.numpy()\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba091f",
   "metadata": {},
   "source": [
    "# Logistic Regression â€“ Classification Report Comparison\n",
    "\n",
    "## 1. Overall Accuracy\n",
    "| Model                | Accuracy |\n",
    "|----------------------|----------|\n",
    "| Before Tuning        | 0.97     |\n",
    "| After Tuning         | **0.98** |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Macro Average\n",
    "| Metric    | Before Tuning | After Tuning |\n",
    "|-----------|---------------|--------------|\n",
    "| Precision | 0.97          | **0.98**     |\n",
    "| Recall    | 0.97          | **0.98**     |\n",
    "| F1-score  | 0.97          | **0.98**     |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Per-Class Performance\n",
    "\n",
    "| Class         | Precision (Before) | Recall (Before) | F1-score (Before) | Precision (After) | Recall (After) | F1-score (After) |\n",
    "|---------------|--------------------|-----------------|-------------------|-------------------|----------------|------------------|\n",
    "| **Business**        | 0.93               | 0.97            | 0.95              | **0.96**          | **0.96**       | **0.96**         |\n",
    "| **Entertainment**   | 0.99               | 0.96            | 0.98              | **1.00**          | **1.00**       | **1.00**         |\n",
    "| **Politics**        | 0.98               | 0.97            | 0.97              | 0.96              | **0.99**       | 0.97             |\n",
    "| **Sport**           | 0.99               | 0.99            | 0.99              | **1.00**          | 0.99           | **1.00**         |\n",
    "| **Tech**            | 0.98               | 0.98            | 0.98              | 0.97              | 0.97           | 0.97             |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Key Observations\n",
    "- **Accuracy improved by 1%** (from 97% to 98%).\n",
    "- **Entertainment** reached perfect scores (1.00 precision, recall, and F1) after tuning.\n",
    "- **Business** improved in precision (0.93 â†’ 0.96) but recall slightly decreased.\n",
    "- **Politics** saw a small drop in precision (0.98 â†’ 0.96) but a notable recall improvement (0.97 â†’ 0.99).\n",
    "- **Sport** achieved perfect precision after tuning.\n",
    "- **Tech** slightly decreased across all three metrics but remained high.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Conclusion\n",
    "Hyperparameter tuning:\n",
    "- Reduced minor misclassifications.\n",
    "- Balanced precision and recall for most classes.\n",
    "- Increased model stability with a small but meaningful accuracy boost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d63710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89255d",
   "metadata": {},
   "source": [
    "### Potential Bias in Training Data\n",
    "- Historical or societal biases present in the source texts can be learned and amplified by the model.\n",
    "- Imbalanced representation of certain categories, groups, or topics may cause skewed predictions.\n",
    "- Language style, dialect, or cultural context differences may reduce fairness and accuracy for underrepresented groups.\n",
    "\n",
    "### Risks of Misclassification\n",
    "- Incorrect predictions could lead to misinformation or poor decision-making in downstream applications.\n",
    "- Mislabeling sensitive content might cause harm to individuals or communities (e.g., false positives in harmful content detection).\n",
    "- Over-reliance on automated outputs without human review can propagate errors at scale.\n",
    "\n",
    "### Mitigation Strategies\n",
    "- Curate and balance datasets to ensure fair representation across categories and demographics.\n",
    "- Regularly audit model outputs for bias and accuracy, especially on sensitive or high-impact use cases.\n",
    "- Implement human-in-the-loop review for critical predictions and enable feedback loops for model improvement.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
